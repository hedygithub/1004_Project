{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "If you want to make big changes, like tuning parameters, please make a new notebook and rename to 'baseline_version_xx' where 'xx' is larger 1 than present version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "# pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/scratch/work/courses/DSGA1004-2021/MSD'\n",
    "TOP=10\n",
    "MODEL_PATH = 'saved_model'.format(getpass.getuser())\n",
    "PREC_AT = 5\n",
    "\n",
    "spark = SparkSession.builder.appName('quq').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading data\n",
      "Successfully loaded the data\n",
      "+--------------------+-----+------------------+-----------------+\n",
      "|             user_id|count|          track_id|__index_level_0__|\n",
      "+--------------------+-----+------------------+-----------------+\n",
      "|00007a02388c208ea...|    1|TRXYDST128F92EC024|                0|\n",
      "+--------------------+-----+------------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "Successfully get unique user/track\n",
      "Successfully get the encoding function\n",
      "Successfully encoding the user and track\n",
      "+------------------+--------------------+-----+-----------------+----------+-----------+\n",
      "|          track_id|             user_id|count|__index_level_0__|user_index|track_index|\n",
      "+------------------+--------------------+-----+-----------------+----------+-----------+\n",
      "|TRAADQX128F422B4CF|7d2b99addaa0a1e2b...|    1|           667178|    198059|        343|\n",
      "+------------------+--------------------+-----+-----------------+----------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "Successfully getting the unique user/track index of val/test\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "print('Begin loading data')\n",
    "\n",
    "train = spark.read.parquet(PATH+'/cf_train.parquet')\n",
    "val = spark.read.parquet(PATH+'/cf_validation.parquet')\n",
    "test = spark.read.parquet(PATH+'/cf_test.parquet')\n",
    "print('Successfully loaded the data')\n",
    "print(test.show(1))\n",
    "\n",
    "# Get Unique user and track\n",
    "unique_user = train.select('user_id').distinct()\n",
    "unique_track = ((train.select('track_id').distinct()) \n",
    "                .union(val.select('track_id').distinct())\n",
    "                .union(test.select('track_id').distinct())).distinct()\n",
    "print('Successfully get unique user/track')\n",
    "\n",
    "# Encode string to index\n",
    "user_to_index = unique_user.rdd.map(itemgetter(0)).zipWithIndex().toDF(['user_id', 'user_index'])\n",
    "track_to_index = unique_track.rdd.map(itemgetter(0)).zipWithIndex().toDF(['track_id', 'track_index'])\n",
    "print('Successfully get the encoding function')\n",
    "train = train.join(user_to_index,['user_id'], how='left')\n",
    "train = train.join(track_to_index,['track_id'], how='left')\n",
    "\n",
    "val = val.join(user_to_index,['user_id'], how='left')\n",
    "val = val.join(track_to_index,['track_id'], how='left')\n",
    "\n",
    "test = test.join(user_to_index,['user_id'], how='left')\n",
    "test = test.join(track_to_index,['track_id'], how='left')     \n",
    "print('Successfully encoding the user and track')\n",
    "print(test.show(1))\n",
    "\n",
    "'''              \n",
    "# Too slow to use StringIndexer() when model.fit()\n",
    "# Encode string to index\n",
    "indexer_user = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\")\n",
    "tran_user = indexer_user.fit(unique_user)\n",
    "indexer_track = StringIndexer(inputCol=\"track_id\", outputCol=\"track_index\")\n",
    "tran_track = indexer_track.fit(unique_track)\n",
    "print('Successfully get the encoding function')\n",
    "\n",
    "train = tran_user.transform(train)\n",
    "val = tran_user.transform(val)\n",
    "test = tran_user.transform(test)\n",
    "print(test.show(1))\n",
    "\n",
    "train = tran_track.transform(train)\n",
    "val = tran_track.transform(val)\n",
    "test = tran_track.transform(test)   \n",
    "print(test.show(1))\n",
    "\n",
    "train = train.withColumn('user_index', train['user_index'].cast('int'))\n",
    "val = val.withColumn('user_index', val['user_index'].cast('int'))\n",
    "test = test.withColumn('user_index', test['user_index'].cast('int'))\n",
    "\n",
    "train = train.withColumn('track_index', train['track_index'].cast('int'))\n",
    "val = val.withColumn('track_index', val['track_index'].cast('int'))\n",
    "test = test.withColumn('track_index', test['track_index'].cast('int'))\n",
    "print('Successfully encoding the user and track')\n",
    "print(test.show(1))\n",
    "''' \n",
    "\n",
    "# Get Unique user index\n",
    "unique_user_index_val, unique_user_index_test = val.select('user_index').distinct(), test.select('user_index').distinct()\n",
    "# unique_track_index_val, unique_track_index_test = val.select('track_index').distinct(), test.select('track_index').distinct()\n",
    "print('Successfully getting the unique user/track index of val/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save the model -- Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully train the model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = ALSModel.load(MODEL_PATH)\n",
    "    print('Successfully load trained model')\n",
    "except:\n",
    "    als = ALS(userCol='user_index', itemCol='track_index', ratingCol='count', \n",
    "              implicitPrefs=True, coldStartStrategy=\"drop\", \n",
    "              rank=10, alpha=0.1, regParam = 0.01)\n",
    "    model = als.fit(train)\n",
    "    model.write().overwrite().save(MODEL_PATH)\n",
    "    print('Successfully train the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model -- Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully get the recommendations\n",
      "Successfully transform the recommendations\n",
      "[(942750, [253051, 84666, 164141, 212289, 49856, 158493, 301157, 343609, 80730, 341667])]\n",
      "Successfully transform the true values\n",
      "[(16530, [26615, 164181, 258741, 268265, 279858, 145044, 193045, 245111, 270113, 299298, 326364, 349302])]\n",
      "Successfully put recommendations and true value together\n",
      "[([299298, 335900, 349302, 326364, 44097, 47952, 245111, 306974, 193045, 270114], [32498, 241350, 111950, 362720, 30578, 189388, 328315, 17120, 47952, 34331, 345537, 380358, 3837])]\n",
      "0.058799999999999984\n"
     ]
    }
   ],
   "source": [
    "userRecs = model.recommendForUserSubset(unique_user_index_val, TOP)\n",
    "print('Successfully get the recommendations')\n",
    "# trackRecsl = model.recommendForItemSubset(unique_track_index_val, TOP)\n",
    "\n",
    "pred_tracks = userRecs.rdd.map(lambda row: (row['user_index'], \n",
    "                                            [track_pred.track_index for track_pred in row['recommendations']]))\n",
    "'''\n",
    "# Use for loop is slowly\n",
    "pred_tracks = []\n",
    "for user, tracks in userRecs.collect():\n",
    "    predict_tracks = [i[0] for i in tracks]\n",
    "    pred_tracks.append((user, predict_tracks))\n",
    "pred_tracks_rdd = spark.sparkContext.parallelize(pred_tracks)\n",
    "'''\n",
    "\n",
    "print('Successfully transform the recommendations')\n",
    "print(pred_tracks_rdd.take(1))\n",
    "\n",
    "w = Window.partitionBy('user_index').orderBy('count')\n",
    "true_tracks = val.withColumn(\n",
    "    'tracks', func.collect_list('track_index').over(w))\\\n",
    "    .groupBy('user_index')\\\n",
    "    .agg(func.max('tracks').alias('tracks'))\n",
    "true_tracks_rdd = true_tracks.rdd.map(tuple)\n",
    "print('Successfully transform the true values')\n",
    "print(true_tracks_rdd.take(1))\n",
    "\n",
    "pred_and_true_tracks = pred_tracks_rdd.join(true_tracks_rdd)\n",
    "pred_and_true_tracks = pred_and_true_tracks.map(lambda tup: tup[1])\n",
    "print('Successfully put recommendations and true value together')\n",
    "print(pred_and_true_tracks.take(1))\n",
    "\n",
    "metrics = RankingMetrics(pred_and_true_tracks)\n",
    "print(metrics.precisionAt(PREC_AT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do: Parameter Tuning\n",
    "Begin your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
